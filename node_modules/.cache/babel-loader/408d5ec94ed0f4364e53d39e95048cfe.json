{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\Jonathan\\\\Documents\\\\GitHub\\\\Egalitarian_Instance_Generator\\\\src\\\\components\\\\SubPages\\\\Auction.js\";\nimport { Container, Wrap, NewH1, NewH2, NewP, Img } from \"./SubpagesElements\";\nimport eg1 from 'images/eg1.PNG';\nimport eg3 from 'images/eg3.PNG';\nimport eg4 from 'images/eg4.PNG';\nimport eg5 from 'images/eg5.PNG';\nimport eg6 from 'images/eg6.PNG';\nimport eg7 from 'images/eg7.PNG';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nconst ThreeSat = () => {\n  return /*#__PURE__*/_jsxDEV(Container, {\n    children: /*#__PURE__*/_jsxDEV(Wrap, {\n      children: [/*#__PURE__*/_jsxDEV(NewH1, {\n        children: \"What is resource allocation?\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 21,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: \"Multiagent Resource Allocation (MARA) deals with the problem of delivering some resources to some agents, given their preferences over the resources. The definition of a particular MARA environment depends on many factors, and the first decision to be addressed is what the goal of the distribution is. In our case, the goal is Egalitarian social welfare. When some resources are to be distributed among a set of agents following this model, the goal is to maximize the utility of the agent whose utility turns out to be minimal. Utility is nothing more than a way of measuring an agent's happiness when the auction has ended. For this reason, before starting the auction, the participating agents must establish certain preferences for the available resources.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 22,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: [\"Some of our previous studies (\", /*#__PURE__*/_jsxDEV(\"a\", {\n          href: \"https://ieeexplore.ieee.org/document/9282975\",\n          children: \"Measuring the benefits of lying in MARA under egalitarian social welfare\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 23,\n          columnNumber: 41\n        }, this), \") have shown that, under certain conditions and rules, it is considerably easy to lie in preferences and obtain a higher utility (profit); when the restrictions on the preferences that agents must communicate for the available resources are not very strong, they are incentivized to communicate a lie in order to monopolize a larger number of resources. At the same time, we show that we are able to discourage this lie if we impose some restrictions on preferences, such as forcing agents to make the sum of preferences for available resources equal to a constant. These two configurations (weak constraint and strong constraint) gave rise to two scenarios: unlimited and limited.\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 23,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewH1, {\n        children: \"Operating modes\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 25,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: [\"The first of the scenarios, known as \", /*#__PURE__*/_jsxDEV(\"b\", {\n          children: \"Unlimited\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 26,\n          columnNumber: 48\n        }, this), \", is one in which each of the preferences that an agent communicates to the auctioneer must be an integer number between (0, 1000). Thus, the set of preferences for an agent considering that there are 10 resources available could be something like this:\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 26,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(Img, {\n        alt: \"dev\",\n        src: eg6\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 27,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: [\"In the second scenario, known as \", /*#__PURE__*/_jsxDEV(\"b\", {\n          children: \"Limited\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 28,\n          columnNumber: 44\n        }, this), \", the sum total of the preferences an agent has for resources must equal 1000. That makes the agent have to think a bit more about what preference he assigns to each resource. In the second of the named articles, we show that agents can obtain a greater benefit by decreasing preferences to appear to be generally less satisfied with the allocation. If we think for a moment, this strategy is considerably difficult to carry out in the Limited scenario for the simple fact that now, when an agent decreases the preference for some resources, then he must necessarily increase the preference for other resources so that in total they still add up to 1000. For example, the set of preferences for an agent considering that there are 10 resources available could be something like this:\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 28,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(Img, {\n        alt: \"dev\",\n        src: eg7\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 29,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: \"In addition, in order to provide a wider variety of instances, we have implemented three instance generators that work in both Unlimited and Limited modes.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 30,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(Img, {\n        alt: \"dev\",\n        src: eg3\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 31,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: \"The difference between these generators is the distribution of preferences that each agent has for the available resources. Specifically, Generator A generates instances giving a random weight to the preference that the agent has for each resource.  Generator B, gives a higher weight to the first resources, decreasing the probability of obtaining larger preferences as preferences are assigned. Finally, Generator C acts like Generator B, but gives a lower weight to the first resources.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 32,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(Img, {\n        alt: \"dev\",\n        src: eg1\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 33,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewH1, {\n        children: \"Types of problem to be solved\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 35,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: \"The application provides two possible solutions for each of the generated instances, regardless of whether it is an Unlimited or Limited instance. The first solution, which we have called \\\"Auction problem\\\", corresponds to the case in which the researcher would like to solve the instance as an auction problem. In this case, the researcher must solve take the instance by running some kind of algorithm that complies with the rules of Egalitarian social welfare, providing a solution to the given problem. Solutions of this type are vectors of n positions, where n is the number of available resources. For each position of the vector, the index of the position indicates the resource being referred to, and the number contained in that position indicates which agent has taken that resource. For example, this could be the solution for an Auction problem where 4 agents participate and 10 resources are available (we assume that the numbering starts from 0: Agent 0, Agent 1, Agent 2 and Agent 3):\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 36,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(Img, {\n        alt: \"dev\",\n        src: eg4\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 37,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: [\"The second problem that a researcher can address is to take the instance as an optimization problem, which we have simply called the \\\"Optimization problem\\\". As we named earlier, some of the studies we have done involve finding out what are the best strategies an agent has for communicating a lie. In the Unlimited case we found that lying is trivial. Therefore, this second optimization problem only makes sense in the Limited case. Specifically, what we are trying to do is to find the best lie that an agent could communicate in the Limited case. Let us understand \\\"the best lie\\\" as the set of preferences with which a given agent would obtain the highest possible payoff. Note that the constraint imposed in the Limited case makes this problem considerably difficult. In fact, as we showed in (\", /*#__PURE__*/_jsxDEV(\"a\", {\n          href: \"https://www.mdpi.com/2227-7390/9/14/1599\",\n          children: \"On the Hardness of Lying under Egalitarian Social Welfare\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 38,\n          columnNumber: 809\n        }, this), \"), the complexity of this problem is one level above NP-Completeness. Despite this, some of our studies using genetic algorithms have shown that it is possible to find considerably good solutions in reasonable times. As an example, the following illustration could be a solution for an Optimization problem in which we have 10 available resources. Note that now we are not interested in which agent obtains which resource, but what we are interested in is which preferences a given agent (the lying agent) should communicate in order to obtain the highest possible benefit. Therefore, each of the ten positions of the vector contains a number between (0, 1000) and, moreover, the sum of all of them must be equal to 1000.\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 38,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(Img, {\n        alt: \"dev\",\n        src: eg5\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 39,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: \"Because we have two possible solutions for each instance, let's say that each instance contains two copies: one to be solved as Auction problem and one to be solved as Optimization problem.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 40,\n        columnNumber: 5\n      }, this), /*#__PURE__*/_jsxDEV(NewP, {\n        children: \"Finally, it should be noted that the application is a random instance generator and nothing more than that. That is, researchers interested in solving problems of this type (such as the two we have proposed), can use this application to generate random and verifiable testbeds, modifying the number of agents and available resources. This application does not perform any kind of computation that has to do with the solutions to the problems. It is the researchers who, using the application, can test their algorithms and put them to the test.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 41,\n        columnNumber: 5\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 20,\n      columnNumber: 4\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 19,\n    columnNumber: 3\n  }, this);\n};\n\n_c = ThreeSat;\nexport default ThreeSat;\n\nvar _c;\n\n$RefreshReg$(_c, \"ThreeSat\");","map":{"version":3,"sources":["C:/Users/Jonathan/Documents/GitHub/Egalitarian_Instance_Generator/src/components/SubPages/Auction.js"],"names":["Container","Wrap","NewH1","NewH2","NewP","Img","eg1","eg3","eg4","eg5","eg6","eg7","ThreeSat"],"mappings":";AAAA,SACCA,SADD,EAECC,IAFD,EAGCC,KAHD,EAICC,KAJD,EAKCC,IALD,EAMCC,GAND,QAOO,oBAPP;AASA,OAAOC,GAAP,MAAgB,gBAAhB;AACA,OAAOC,GAAP,MAAgB,gBAAhB;AACA,OAAOC,GAAP,MAAgB,gBAAhB;AACA,OAAOC,GAAP,MAAgB,gBAAhB;AACA,OAAOC,GAAP,MAAgB,gBAAhB;AACA,OAAOC,GAAP,MAAgB,gBAAhB;;;AAEA,MAAMC,QAAQ,GAAG,MAAM;AACtB,sBACC,QAAC,SAAD;AAAA,2BACC,QAAC,IAAD;AAAA,8BACC,QAAC,KAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADD,eAEC,QAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAFD,eAGC,QAAC,IAAD;AAAA,kEAAoC;AAAG,UAAA,IAAI,EAAC,8CAAR;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAApC;AAAA;AAAA;AAAA;AAAA;AAAA,cAHD,eAKC,QAAC,KAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cALD,eAMC,QAAC,IAAD;AAAA,yEAA2C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAA3C;AAAA;AAAA;AAAA;AAAA;AAAA,cAND,eAOC,QAAC,GAAD;AAAK,QAAA,GAAG,EAAC,KAAT;AAAe,QAAA,GAAG,EAAEF;AAApB;AAAA;AAAA;AAAA;AAAA,cAPD,eAQC,QAAC,IAAD;AAAA,qEAAuC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAAvC;AAAA;AAAA;AAAA;AAAA;AAAA,cARD,eASC,QAAC,GAAD;AAAK,QAAA,GAAG,EAAC,KAAT;AAAe,QAAA,GAAG,EAAEC;AAApB;AAAA;AAAA;AAAA;AAAA,cATD,eAUC,QAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAVD,eAWC,QAAC,GAAD;AAAK,QAAA,GAAG,EAAC,KAAT;AAAe,QAAA,GAAG,EAAEJ;AAApB;AAAA;AAAA;AAAA;AAAA,cAXD,eAYC,QAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAZD,eAaC,QAAC,GAAD;AAAK,QAAA,GAAG,EAAC,KAAT;AAAe,QAAA,GAAG,EAAED;AAApB;AAAA;AAAA;AAAA;AAAA,cAbD,eAeC,QAAC,KAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAfD,eAgBC,QAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAhBD,eAiBC,QAAC,GAAD;AAAK,QAAA,GAAG,EAAC,KAAT;AAAe,QAAA,GAAG,EAAEE;AAApB;AAAA;AAAA;AAAA;AAAA,cAjBD,eAkBC,QAAC,IAAD;AAAA,s0BAAoyB;AAAG,UAAA,IAAI,EAAC,0CAAR;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,gBAApyB;AAAA;AAAA;AAAA;AAAA;AAAA,cAlBD,eAmBC,QAAC,GAAD;AAAK,QAAA,GAAG,EAAC,KAAT;AAAe,QAAA,GAAG,EAAEC;AAApB;AAAA;AAAA;AAAA;AAAA,cAnBD,eAoBC,QAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cApBD,eAqBC,QAAC,IAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cArBD;AAAA;AAAA;AAAA;AAAA;AAAA;AADD;AAAA;AAAA;AAAA;AAAA,UADD;AA4BA,CA7BD;;KAAMG,Q;AA+BN,eAAeA,QAAf","sourcesContent":["import {\n\tContainer,\n\tWrap,\n\tNewH1,\n\tNewH2,\n\tNewP,\n\tImg\n} from \"./SubpagesElements\";\n\nimport eg1 from 'images/eg1.PNG';\nimport eg3 from 'images/eg3.PNG';\nimport eg4 from 'images/eg4.PNG';\nimport eg5 from 'images/eg5.PNG';\nimport eg6 from 'images/eg6.PNG';\nimport eg7 from 'images/eg7.PNG';\n\nconst ThreeSat = () => {\n\treturn (\n\t\t<Container>\n\t\t\t<Wrap>\n\t\t\t\t<NewH1>What is resource allocation?</NewH1>\n\t\t\t\t<NewP>Multiagent Resource Allocation (MARA) deals with the problem of delivering some resources to some agents, given their preferences over the resources. The definition of a particular MARA environment depends on many factors, and the first decision to be addressed is what the goal of the distribution is. In our case, the goal is Egalitarian social welfare. When some resources are to be distributed among a set of agents following this model, the goal is to maximize the utility of the agent whose utility turns out to be minimal. Utility is nothing more than a way of measuring an agent's happiness when the auction has ended. For this reason, before starting the auction, the participating agents must establish certain preferences for the available resources.</NewP>\n\t\t\t\t<NewP>Some of our previous studies (<a href=\"https://ieeexplore.ieee.org/document/9282975\">Measuring the benefits of lying in MARA under egalitarian social welfare</a>) have shown that, under certain conditions and rules, it is considerably easy to lie in preferences and obtain a higher utility (profit); when the restrictions on the preferences that agents must communicate for the available resources are not very strong, they are incentivized to communicate a lie in order to monopolize a larger number of resources. At the same time, we show that we are able to discourage this lie if we impose some restrictions on preferences, such as forcing agents to make the sum of preferences for available resources equal to a constant. These two configurations (weak constraint and strong constraint) gave rise to two scenarios: unlimited and limited.</NewP>\n\n\t\t\t\t<NewH1>Operating modes</NewH1>\n\t\t\t\t<NewP>The first of the scenarios, known as <b>Unlimited</b>, is one in which each of the preferences that an agent communicates to the auctioneer must be an integer number between (0, 1000). Thus, the set of preferences for an agent considering that there are 10 resources available could be something like this:</NewP>\n\t\t\t\t<Img alt=\"dev\" src={eg6}></Img>\n\t\t\t\t<NewP>In the second scenario, known as <b>Limited</b>, the sum total of the preferences an agent has for resources must equal 1000. That makes the agent have to think a bit more about what preference he assigns to each resource. In the second of the named articles, we show that agents can obtain a greater benefit by decreasing preferences to appear to be generally less satisfied with the allocation. If we think for a moment, this strategy is considerably difficult to carry out in the Limited scenario for the simple fact that now, when an agent decreases the preference for some resources, then he must necessarily increase the preference for other resources so that in total they still add up to 1000. For example, the set of preferences for an agent considering that there are 10 resources available could be something like this:</NewP>\n\t\t\t\t<Img alt=\"dev\" src={eg7}></Img>\n\t\t\t\t<NewP>In addition, in order to provide a wider variety of instances, we have implemented three instance generators that work in both Unlimited and Limited modes.</NewP>\n\t\t\t\t<Img alt=\"dev\" src={eg3}></Img>\n\t\t\t\t<NewP>The difference between these generators is the distribution of preferences that each agent has for the available resources. Specifically, Generator A generates instances giving a random weight to the preference that the agent has for each resource.  Generator B, gives a higher weight to the first resources, decreasing the probability of obtaining larger preferences as preferences are assigned. Finally, Generator C acts like Generator B, but gives a lower weight to the first resources.</NewP>\n\t\t\t\t<Img alt=\"dev\" src={eg1}></Img>\n\n\t\t\t\t<NewH1>Types of problem to be solved</NewH1>\n\t\t\t\t<NewP>The application provides two possible solutions for each of the generated instances, regardless of whether it is an Unlimited or Limited instance. The first solution, which we have called \"Auction problem\", corresponds to the case in which the researcher would like to solve the instance as an auction problem. In this case, the researcher must solve take the instance by running some kind of algorithm that complies with the rules of Egalitarian social welfare, providing a solution to the given problem. Solutions of this type are vectors of n positions, where n is the number of available resources. For each position of the vector, the index of the position indicates the resource being referred to, and the number contained in that position indicates which agent has taken that resource. For example, this could be the solution for an Auction problem where 4 agents participate and 10 resources are available (we assume that the numbering starts from 0: Agent 0, Agent 1, Agent 2 and Agent 3):</NewP>\n\t\t\t\t<Img alt=\"dev\" src={eg4}></Img>\n\t\t\t\t<NewP>The second problem that a researcher can address is to take the instance as an optimization problem, which we have simply called the \"Optimization problem\". As we named earlier, some of the studies we have done involve finding out what are the best strategies an agent has for communicating a lie. In the Unlimited case we found that lying is trivial. Therefore, this second optimization problem only makes sense in the Limited case. Specifically, what we are trying to do is to find the best lie that an agent could communicate in the Limited case. Let us understand \"the best lie\" as the set of preferences with which a given agent would obtain the highest possible payoff. Note that the constraint imposed in the Limited case makes this problem considerably difficult. In fact, as we showed in (<a href=\"https://www.mdpi.com/2227-7390/9/14/1599\">On the Hardness of Lying under Egalitarian Social Welfare</a>), the complexity of this problem is one level above NP-Completeness. Despite this, some of our studies using genetic algorithms have shown that it is possible to find considerably good solutions in reasonable times. As an example, the following illustration could be a solution for an Optimization problem in which we have 10 available resources. Note that now we are not interested in which agent obtains which resource, but what we are interested in is which preferences a given agent (the lying agent) should communicate in order to obtain the highest possible benefit. Therefore, each of the ten positions of the vector contains a number between (0, 1000) and, moreover, the sum of all of them must be equal to 1000.</NewP>\n\t\t\t\t<Img alt=\"dev\" src={eg5}></Img>\n\t\t\t\t<NewP>Because we have two possible solutions for each instance, let's say that each instance contains two copies: one to be solved as Auction problem and one to be solved as Optimization problem.</NewP>\n\t\t\t\t<NewP>Finally, it should be noted that the application is a random instance generator and nothing more than that. That is, researchers interested in solving problems of this type (such as the two we have proposed), can use this application to generate random and verifiable testbeds, modifying the number of agents and available resources. This application does not perform any kind of computation that has to do with the solutions to the problems. It is the researchers who, using the application, can test their algorithms and put them to the test.</NewP>\n\n\t\t\t</Wrap>\n\t\t</Container>\n\t);\n}\n\nexport default ThreeSat;"]},"metadata":{},"sourceType":"module"}